{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadkhi/GSoC-2025-Task/blob/main/Specific_Test_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth, drive\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# Authentication for Google Drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Folder ID from the shared link\n",
        "folder_id = \"1-91y1fQHanXfzx5WUy0qLroflfgVnk_L\"\n",
        "\n",
        "# Destination in your Google Drive\n",
        "destination = \"/content/drive/My Drive/dataset\"\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "# Use gdown to download the folder\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=destination, quiet=False, use_cookies=False)\n",
        "\n",
        "print(\"Download complete! Files saved in:\", destination)"
      ],
      "metadata": {
        "id": "D-feVZqnTzYg",
        "outputId": "a4881dc4-d2d1-415a-977f-90b14440409b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1fVNbU1JafuXm3fQURiReKLlCQWSTdEaR Buendia - Instruccion.pdf\n",
            "Processing file 1gi2PBP8uoQ0EGD8AjQkDvMLZufJhvhM2 Constituciones sinodales Calahorra 1602.pdf\n",
            "Processing file 1HNMX8iYw6BFb5ZKVmsnQ8zl83FifVhKD ES-AHPHU - J-000312-0014 – 1579.pdf\n",
            "Processing file 14-p__cXNGhIDzTEbtgCFX3UyG8kryZ0w Ezcaray - Vozes.pdf\n",
            "Processing file 1xZUicnmIWhr06UWXc0RP5iqPImtZFTsS J&#x3a;0017&#x3a;03-J&#x3a;0085&#x3a;11 – 1799-1845.pdf\n",
            "Processing file 1xLrWVn9jAxM7arqNV1VikHtH64XPnqzy Mendo - Principe perfecto.pdf\n",
            "Processing file 1KHvG8U9W9p8u8QooF4MCqWkVZ-cRJQ7H Paredes - Reglas generales.pdf\n",
            "Processing file 1k0L954A4iqENkMzXO-KVZu0S9lntm4n1 PORCONES.228.35 – 1636.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fVNbU1JafuXm3fQURiReKLlCQWSTdEaR\n",
            "To: /content/drive/My Drive/data/Buendia - Instruccion.pdf\n",
            "100%|██████████| 3.29M/3.29M [00:00<00:00, 33.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gi2PBP8uoQ0EGD8AjQkDvMLZufJhvhM2\n",
            "To: /content/drive/My Drive/data/Constituciones sinodales Calahorra 1602.pdf\n",
            "100%|██████████| 1.81M/1.81M [00:00<00:00, 18.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HNMX8iYw6BFb5ZKVmsnQ8zl83FifVhKD\n",
            "To: /content/drive/My Drive/data/ES-AHPHU - J-000312-0014 – 1579.pdf\n",
            "100%|██████████| 8.44M/8.44M [00:00<00:00, 31.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14-p__cXNGhIDzTEbtgCFX3UyG8kryZ0w\n",
            "To: /content/drive/My Drive/data/Ezcaray - Vozes.pdf\n",
            "100%|██████████| 3.44M/3.44M [00:00<00:00, 28.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xZUicnmIWhr06UWXc0RP5iqPImtZFTsS\n",
            "To: /content/drive/My Drive/data/J&#x3a;0017&#x3a;03-J&#x3a;0085&#x3a;11 – 1799-1845.pdf\n",
            "100%|██████████| 12.6M/12.6M [00:00<00:00, 76.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xLrWVn9jAxM7arqNV1VikHtH64XPnqzy\n",
            "To: /content/drive/My Drive/data/Mendo - Principe perfecto.pdf\n",
            "100%|██████████| 2.37M/2.37M [00:00<00:00, 22.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KHvG8U9W9p8u8QooF4MCqWkVZ-cRJQ7H\n",
            "To: /content/drive/My Drive/data/Paredes - Reglas generales.pdf\n",
            "100%|██████████| 3.82M/3.82M [00:00<00:00, 31.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k0L954A4iqENkMzXO-KVZu0S9lntm4n1\n",
            "To: /content/drive/My Drive/data/PORCONES.228.35 – 1636.pdf\n",
            "100%|██████████| 37.9M/37.9M [00:00<00:00, 47.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete! Files saved in: /content/drive/My Drive/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "CDQmfNZBOoix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from pdf2image import convert_from_path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import jaccard_score, f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e951zZPnM_JM",
        "outputId": "094f60b6-957e-4535-e57c-c83da446ad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "pdf_folder_path = \"/content/drive/My Drive/dataset/\"  # Folder containing PDFs\n",
        "output_image_folder = \"/content/pdf_images\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "if not os.path.exists(output_image_folder):\n",
        "    os.makedirs(output_image_folder)\n",
        "\n",
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    base_filename = os.path.splitext(os.path.basename(pdf_path))[0] # get filename without extension\n",
        "    for i, image in enumerate(images):\n",
        "        image.save(os.path.join(output_folder, f\"{base_filename}_page_{i}.jpg\"), \"JPEG\")\n",
        "\n",
        "# Convert all PDFs to images\n",
        "pdf_files = [f for f in os.listdir(pdf_folder_path) if f.endswith(\".pdf\")]\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
        "    pdf_to_images(pdf_path, output_image_folder)\n",
        "\n",
        "# Load images and masks\n",
        "image_paths = [os.path.join(output_image_folder, f) for f in os.listdir(output_image_folder) if f.endswith(\".jpg\")]\n",
        "images = [cv2.imread(path) for path in image_paths]\n",
        "\n",
        "# Function to create simple masks (replace with your actual mask creation)\n",
        "def create_masks(image_paths):\n",
        "    masks = []\n",
        "    for image_path in image_paths:\n",
        "        img = cv2.imread(image_path)\n",
        "        mask = np.zeros_like(img[:, :, 0], dtype=np.uint8)\n",
        "        mask[100:img.shape[0]-100, 100:img.shape[1]-100] = 255\n",
        "        masks.append(mask)\n",
        "    return masks\n",
        "\n",
        "masks = create_masks(image_paths)\n",
        "\n",
        "# Normalize images and create numpy arrays\n",
        "images = [img / 255.0 for img in images]\n",
        "resized_images = [cv2.resize(img, (256, 256)) for img in images]\n",
        "resized_masks = [cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST) / 255.0 for mask in masks]\n",
        "X = np.array(resized_images)\n",
        "y = np.array(resized_masks)[:, :, :, np.newaxis]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# U-Net model\n",
        "def build_unet(input_shape=(256, 256, 3)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    # Bottleneck\n",
        "    conv_mid = layers.Conv2D(256, 3, activation='relu', padding='same')(pool1)\n",
        "    conv_mid = layers.Conv2D(256, 3, activation='relu', padding='same')(conv_mid)\n",
        "    # Decoder\n",
        "    up7 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv_mid)\n",
        "    merge7 = layers.concatenate([up7, conv1], axis=3)\n",
        "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge7) # Corrected line\n",
        "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = build_unet()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with ImageDataGenerator\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "          steps_per_epoch=int(len(X_train) / 32),\n",
        "          epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "# Calculate IoU and F1-score\n",
        "iou = jaccard_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "f1 = f1_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "\n",
        "print(f\"Test IoU: {iou}, Test F1-Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjDDCWtfDfNp",
        "outputId": "e4f573fe-fc92-47bf-965e-dfbbc8e5f93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (94080000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (94080000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCPx2VHNYDuy",
        "outputId": "0802093d-18f2-4f98-ba8d-50ce727d3e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8068084716796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsM-OnX9aPt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}