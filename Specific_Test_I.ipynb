{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadkhi/GSoC-2025-Task/blob/main/Specific_Test_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth, drive\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# Authentication for Google Drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Folder ID from the shared link\n",
        "folder_id = \"1-91y1fQHanXfzx5WUy0qLroflfgVnk_L\"\n",
        "\n",
        "# Destination in your Google Drive\n",
        "destination = \"/content/drive/My Drive/data\"\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "# Use gdown to download the folder\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=destination, quiet=False, use_cookies=False)\n",
        "\n",
        "print(\"Download complete! Files saved in:\", destination)\n",
        "\n",
        "\n",
        "\n",
        "PDF_PATH_1 = \"/content/drive/My Drive/data/Ezcaray - Vozes.pdf\"  # Adjust if needed\n",
        "PDF_PATH_2 = \"/content/drive/My Drive/data/Constituciones sinodales Calahorra 1602.pdf\"  # Adjust if needed\n",
        "IMAGE_DIR = \"/content/drive/My Drive/data/images\"  # Create images in 'data' folder\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "D-feVZqnTzYg",
        "outputId": "e6ae68fc-6df8-45d8-9466-d9edf4ba0b37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1-JaE5tNwyNHGDG60GHVihshifrVGgRKj Ezcaray - Vozes.pdf\n",
            "Processing file 1-7pV-zFu6cVuty3wRhjMTN3XbpBhQzHC Mendo - Principe perfecto.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-JaE5tNwyNHGDG60GHVihshifrVGgRKj\n",
            "To: /content/drive/My Drive/data/Ezcaray - Vozes.pdf\n",
            "100%|██████████| 3.44M/3.44M [00:00<00:00, 44.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7pV-zFu6cVuty3wRhjMTN3XbpBhQzHC\n",
            "To: /content/drive/My Drive/data/Mendo - Principe perfecto.pdf\n",
            "100%|██████████| 2.37M/2.37M [00:00<00:00, 22.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete! Files saved in: /content/drive/My Drive/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "CDQmfNZBOoix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from pdf2image import convert_from_path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import jaccard_score, f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e951zZPnM_JM",
        "outputId": "2ac4b1ab-c973-4948-c9de-7f24c7114cf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "pdf_folder_path = \"/content/drive/My Drive/data/Ezcaray - Vozes.pdf\"\n",
        "output_image_folder = \"/content/pdf_images\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "if not os.path.exists(output_image_folder):\n",
        "    os.makedirs(output_image_folder)\n",
        "\n",
        "# Function to convert PDF to images\n",
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    for i, image in enumerate(images):\n",
        "        image.save(os.path.join(output_folder, f\"page_{i}.jpg\"), \"JPEG\")\n",
        "\n",
        "# Convert PDF to images\n",
        "pdf_to_images(pdf_folder_path, output_image_folder)\n",
        "\n",
        "# Function to create simple masks (replace with your actual mask creation)\n",
        "def create_masks(image_paths):\n",
        "    masks = []\n",
        "    for image_path in image_paths:\n",
        "        img = cv2.imread(image_path)\n",
        "        mask = np.zeros_like(img[:, :, 0], dtype=np.uint8)\n",
        "        mask[100:img.shape[0]-100, 100:img.shape[1]-100] = 255\n",
        "        masks.append(mask)\n",
        "    return masks\n",
        "\n",
        "# Load images and masks\n",
        "image_paths = [os.path.join(output_image_folder, f) for f in os.listdir(output_image_folder) if f.endswith(\".jpg\")]\n",
        "images = [cv2.imread(path) for path in image_paths]\n",
        "masks = create_masks(image_paths)\n",
        "\n",
        "# Normalize images\n",
        "images = [img / 255.0 for img in images]\n",
        "\n",
        "# Resize images and masks\n",
        "resized_images = [cv2.resize(img, (256, 256)) for img in images]\n",
        "resized_masks = [cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST) / 255.0 for mask in masks]\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(resized_images)\n",
        "y = np.array(resized_masks)[:, :, :, np.newaxis]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# U-Net model enhanced with attention\n",
        "def build_unet(input_shape=(256, 256, 3)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    # ... (Add more encoder layers)\n",
        "    # Bottleneck\n",
        "    conv_mid = layers.Conv2D(256, 3, activation='relu', padding='same')(pool1)\n",
        "    conv_mid = layers.Conv2D(256, 3, activation='relu', padding='same')(conv_mid)\n",
        "    # Decoder\n",
        "    up7 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv_mid)\n",
        "    merge7 = layers.concatenate([up7, conv1], axis=3)\n",
        "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = build_unet()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with ImageDataGenerator\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "          steps_per_epoch=int(len(X_train) / 32),  # Corrected line\n",
        "          epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "# Calculate IoU and F1-score\n",
        "iou = jaccard_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "f1 = f1_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "\n",
        "print(f\"Test IoU: {iou}, Test F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "OjDDCWtfDfNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test.flatten(), y_pred_binary.flatten())\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCPx2VHNYDuy",
        "outputId": "0802093d-18f2-4f98-ba8d-50ce727d3e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8068084716796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsM-OnX9aPt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}